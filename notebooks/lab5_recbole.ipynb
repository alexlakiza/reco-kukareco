{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7rPKdz1EvrD"
      },
      "source": [
        "## Устанавливаем необходимые библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h82_sQazGPAN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b15d5ecb-17b0-4c08-ff72-fc87398dda55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "pip install -q recbole ray kmeans_pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LauYSfeXE5A9"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHWXW-1ZEoWu"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import time\n",
        "\n",
        "from collections import Counter\n",
        "from random import randint, random\n",
        "from scipy.sparse import coo_matrix, hstack\n",
        "from sklearn.metrics.pairwise import euclidean_distances, cosine_distances, cosine_similarity\n",
        "\n",
        "import logging\n",
        "from logging import getLogger\n",
        "from recbole.config import Config\n",
        "from recbole.data import create_dataset, data_preparation\n",
        "from recbole.model.sequential_recommender import GRU4Rec, Caser\n",
        "from recbole.trainer import Trainer\n",
        "from recbole.utils import init_seed, init_logger\n",
        "from recbole.quick_start import run_recbole\n",
        "\n",
        "import torch\n",
        "from recbole.model.general_recommender.multivae import MultiVAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OuCcazDFMxT"
      },
      "source": [
        "## Загружаем данные"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Код с семинара:"
      ],
      "metadata": {
        "id": "lbO8_kZ-YYfN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sb5uwe5-FerS"
      },
      "outputs": [],
      "source": [
        "interactions_df = pd.read_csv('interactions_processed_kion.csv')\n",
        "users_df = pd.read_csv('users_processed_kion.csv')\n",
        "items_df = pd.read_csv('items_processed_kion.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfbJrMLeFl6f"
      },
      "outputs": [],
      "source": [
        "interactions_df['t_dat'] = pd.to_datetime(interactions_df['last_watch_dt'], format=\"%Y-%m-%d\")\n",
        "interactions_df['timestamp'] = interactions_df.t_dat.values.astype(np.int64) // 10 ** 9\n",
        "\n",
        "df = interactions_df[['user_id', 'item_id', 'timestamp']].rename(\n",
        "    columns={'user_id': 'user_id:token', 'item_id': 'item_id:token', 'timestamp': 'timestamp:float'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJRBa0YMF2JQ"
      },
      "outputs": [],
      "source": [
        "!mkdir recbox_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHwadofEF5N-"
      },
      "outputs": [],
      "source": [
        "df.to_csv('recbox_data/recbox_data.inter', index=False, sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MBDekS4F9Pe",
        "outputId": "278ce223-7257-4fc1-8b8c-13d674900261"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:command line args [-f /root/.local/share/jupyter/runtime/kernel-38adbd9a-5a34-47f0-bcee-cd772e2c89d3.json] will not be used in RecBole\n"
          ]
        }
      ],
      "source": [
        "parameter_dict = {\n",
        "    'data_path': '',\n",
        "    'USER_ID_FIELD': 'user_id',\n",
        "    'ITEM_ID_FIELD': 'item_id',\n",
        "    'TIME_FIELD': 'timestamp',\n",
        "    'device': 'GPU',\n",
        "    'user_inter_num_interval': \"[40,inf)\",\n",
        "    'item_inter_num_interval': \"[40,inf)\",\n",
        "    'load_col': {'inter': ['user_id', 'item_id', 'timestamp']},\n",
        "    'neg_sampling': None,\n",
        "    'epochs': 10,\n",
        "    'eval_args': {\n",
        "        'split': {'RS': [9, 0, 1]},\n",
        "        'group_by': 'user',\n",
        "        'order': 'TO',\n",
        "        'mode': 'full'}\n",
        "}\n",
        "config = Config(model='MultiVAE', dataset='recbox_data', config_dict=parameter_dict)\n",
        "\n",
        "# init random seed\n",
        "init_seed(config['seed'], config['reproducibility'])\n",
        "\n",
        "# logger initialization\n",
        "init_logger(config)\n",
        "logger = getLogger()\n",
        "# Create handlers\n",
        "c_handler = logging.StreamHandler()\n",
        "c_handler.setLevel(logging.INFO)\n",
        "logger.addHandler(c_handler)\n",
        "\n",
        "# write config info into log\n",
        "# logger.info(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wz_9fk_zF_Hf"
      },
      "outputs": [],
      "source": [
        "dataset = create_dataset(config)\n",
        "logger.info(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBF4dVufGBUg"
      },
      "outputs": [],
      "source": [
        "# dataset splitting\n",
        "train_data, valid_data, test_data = data_preparation(config, dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучаем модели"
      ],
      "metadata": {
        "id": "ppEXgt_hYaU2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOoFfCC3GMOE",
        "outputId": "d193fc48-63c7-4368-9b05-53dbda6ab7e3"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running MultiVAE...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:command line args [-f /root/.local/share/jupyter/runtime/kernel-ffe82819-fe22-4eb8-992f-4401f79ca9dd.json] will not be used in RecBole\n",
            "command line args [-f /root/.local/share/jupyter/runtime/kernel-ffe82819-fe22-4eb8-992f-4401f79ca9dd.json] will not be used in RecBole\n",
            "WARNING:root:Max value of user's history interaction records has reached 20.9471766848816% of the total.\n",
            "Max value of user's history interaction records has reached 20.9471766848816% of the total.\n",
            "Train     0: 100%|███████████████████████████| 7/7 [00:00<00:00, 15.75it/s, GPU RAM: 0.38 G/14.75 G]\n",
            "Train     1: 100%|███████████████████████████| 7/7 [00:00<00:00, 19.91it/s, GPU RAM: 0.38 G/14.75 G]\n",
            "Train     2: 100%|███████████████████████████| 7/7 [00:00<00:00, 20.03it/s, GPU RAM: 0.38 G/14.75 G]\n",
            "Train     3: 100%|███████████████████████████| 7/7 [00:00<00:00, 19.64it/s, GPU RAM: 0.38 G/14.75 G]\n",
            "Train     4: 100%|███████████████████████████| 7/7 [00:00<00:00, 18.83it/s, GPU RAM: 0.38 G/14.75 G]\n",
            "Train     5: 100%|███████████████████████████| 7/7 [00:00<00:00, 20.05it/s, GPU RAM: 0.38 G/14.75 G]\n",
            "Train     6: 100%|███████████████████████████| 7/7 [00:00<00:00, 19.57it/s, GPU RAM: 0.38 G/14.75 G]\n",
            "Train     7: 100%|███████████████████████████| 7/7 [00:00<00:00, 18.45it/s, GPU RAM: 0.38 G/14.75 G]\n",
            "Train     8: 100%|███████████████████████████| 7/7 [00:00<00:00, 19.48it/s, GPU RAM: 0.38 G/14.75 G]\n",
            "Train     9: 100%|███████████████████████████| 7/7 [00:00<00:00, 19.37it/s, GPU RAM: 0.38 G/14.75 G]\n",
            "Evaluate   : 100%|██████████████████| 13354/13354 [02:11<00:00, 101.74it/s, GPU RAM: 0.38 G/14.75 G]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It took 3.19 mins\n",
            "{'best_valid_score': -inf, 'valid_score_bigger': True, 'best_valid_result': None, 'test_result': OrderedDict([('recall@10', 0.0834), ('mrr@10', 0.1671), ('ndcg@10', 0.0816), ('hit@10', 0.3466), ('precision@10', 0.0462)])}\n",
            "========================================\n",
            "running MultiDAE...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:command line args [-f /root/.local/share/jupyter/runtime/kernel-ffe82819-fe22-4eb8-992f-4401f79ca9dd.json] will not be used in RecBole\n",
            "command line args [-f /root/.local/share/jupyter/runtime/kernel-ffe82819-fe22-4eb8-992f-4401f79ca9dd.json] will not be used in RecBole\n",
            "WARNING:root:Max value of user's history interaction records has reached 20.9471766848816% of the total.\n",
            "Max value of user's history interaction records has reached 20.9471766848816% of the total.\n",
            "Train     0: 100%|███████████████████████████| 7/7 [00:00<00:00, 12.48it/s, GPU RAM: 0.38 G/14.75 G]\n",
            "Train     1: 100%|███████████████████████████| 7/7 [00:00<00:00,  8.58it/s, GPU RAM: 0.38 G/14.75 G]\n",
            "Train     2: 100%|███████████████████████████| 7/7 [00:01<00:00,  5.67it/s, GPU RAM: 0.38 G/14.75 G]\n",
            "Train     3: 100%|███████████████████████████| 7/7 [00:00<00:00, 11.32it/s, GPU RAM: 0.38 G/14.75 G]\n",
            "Train     4: 100%|███████████████████████████| 7/7 [00:00<00:00, 12.06it/s, GPU RAM: 0.40 G/14.75 G]\n",
            "Train     5: 100%|███████████████████████████| 7/7 [00:02<00:00,  2.86it/s, GPU RAM: 0.40 G/14.75 G]\n",
            "Train     6: 100%|███████████████████████████| 7/7 [00:00<00:00, 13.85it/s, GPU RAM: 0.40 G/14.75 G]\n",
            "Train     7: 100%|███████████████████████████| 7/7 [00:00<00:00,  9.64it/s, GPU RAM: 0.40 G/14.75 G]\n",
            "Train     8: 100%|███████████████████████████| 7/7 [00:10<00:00,  1.49s/it, GPU RAM: 0.40 G/14.75 G]\n",
            "Train     9: 100%|███████████████████████████| 7/7 [00:00<00:00, 20.70it/s, GPU RAM: 0.40 G/14.75 G]\n",
            "Evaluate   : 100%|███████████████████| 13354/13354 [02:46<00:00, 80.21it/s, GPU RAM: 0.40 G/14.75 G]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It took 4.80 mins\n",
            "{'best_valid_score': -inf, 'valid_score_bigger': True, 'best_valid_result': None, 'test_result': OrderedDict([('recall@10', 0.0837), ('mrr@10', 0.1657), ('ndcg@10', 0.0814), ('hit@10', 0.3466), ('precision@10', 0.0463)])}\n",
            "========================================\n",
            "running MacridVAE...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:command line args [-f /root/.local/share/jupyter/runtime/kernel-ffe82819-fe22-4eb8-992f-4401f79ca9dd.json] will not be used in RecBole\n",
            "command line args [-f /root/.local/share/jupyter/runtime/kernel-ffe82819-fe22-4eb8-992f-4401f79ca9dd.json] will not be used in RecBole\n",
            "WARNING:root:Max value of user's history interaction records has reached 20.9471766848816% of the total.\n",
            "Max value of user's history interaction records has reached 20.9471766848816% of the total.\n",
            "Train     0: 100%|███████████████████████████| 7/7 [00:01<00:00,  3.60it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     1: 100%|███████████████████████████| 7/7 [00:01<00:00,  3.79it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     2: 100%|███████████████████████████| 7/7 [00:01<00:00,  3.53it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     3: 100%|███████████████████████████| 7/7 [00:02<00:00,  2.70it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     4: 100%|███████████████████████████| 7/7 [00:02<00:00,  3.35it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     5: 100%|███████████████████████████| 7/7 [00:01<00:00,  3.71it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     6: 100%|███████████████████████████| 7/7 [00:01<00:00,  3.67it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     7: 100%|███████████████████████████| 7/7 [00:01<00:00,  3.68it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     8: 100%|███████████████████████████| 7/7 [00:01<00:00,  3.74it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     9: 100%|███████████████████████████| 7/7 [00:02<00:00,  2.95it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Evaluate   : 100%|███████████████████| 13354/13354 [06:26<00:00, 34.52it/s, GPU RAM: 0.95 G/14.75 G]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It took 8.60 mins\n",
            "{'best_valid_score': -inf, 'valid_score_bigger': True, 'best_valid_result': None, 'test_result': OrderedDict([('recall@10', 0.0827), ('mrr@10', 0.1548), ('ndcg@10', 0.0775), ('hit@10', 0.3469), ('precision@10', 0.0455)])}\n",
            "========================================\n",
            "running NeuMF...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:command line args [-f /root/.local/share/jupyter/runtime/kernel-ffe82819-fe22-4eb8-992f-4401f79ca9dd.json] will not be used in RecBole\n",
            "command line args [-f /root/.local/share/jupyter/runtime/kernel-ffe82819-fe22-4eb8-992f-4401f79ca9dd.json] will not be used in RecBole\n",
            "Train     0: 100%|███████████████████████| 755/755 [00:34<00:00, 21.58it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     1: 100%|███████████████████████| 755/755 [00:35<00:00, 21.09it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     2: 100%|███████████████████████| 755/755 [00:36<00:00, 20.93it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     3: 100%|███████████████████████| 755/755 [00:35<00:00, 21.34it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     4: 100%|███████████████████████| 755/755 [00:35<00:00, 21.56it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     5: 100%|███████████████████████| 755/755 [00:35<00:00, 21.53it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     6: 100%|███████████████████████| 755/755 [00:34<00:00, 21.67it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     7: 100%|███████████████████████| 755/755 [00:35<00:00, 21.37it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     8: 100%|███████████████████████| 755/755 [00:35<00:00, 21.33it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     9: 100%|███████████████████████| 755/755 [00:35<00:00, 21.27it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Evaluate   : 100%|███████████████████| 13354/13354 [03:27<00:00, 64.40it/s, GPU RAM: 0.95 G/14.75 G]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It took 10.09 mins\n",
            "{'best_valid_score': -inf, 'valid_score_bigger': True, 'best_valid_result': None, 'test_result': OrderedDict([('recall@10', 0.0687), ('mrr@10', 0.1181), ('ndcg@10', 0.0607), ('hit@10', 0.3008), ('precision@10', 0.038)])}\n",
            "========================================\n",
            "running RecVAE...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:command line args [-f /root/.local/share/jupyter/runtime/kernel-ffe82819-fe22-4eb8-992f-4401f79ca9dd.json] will not be used in RecBole\n",
            "command line args [-f /root/.local/share/jupyter/runtime/kernel-ffe82819-fe22-4eb8-992f-4401f79ca9dd.json] will not be used in RecBole\n",
            "WARNING:root:Max value of user's history interaction records has reached 20.9471766848816% of the total.\n",
            "Max value of user's history interaction records has reached 20.9471766848816% of the total.\n",
            "Train     0: 100%|███████████████████████████| 7/7 [00:00<00:00,  8.75it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     0: 100%|███████████████████████████| 7/7 [00:00<00:00,  8.86it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     0: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.41it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     0: 100%|███████████████████████████| 7/7 [00:01<00:00,  6.93it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     1: 100%|███████████████████████████| 7/7 [00:01<00:00,  6.58it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     1: 100%|███████████████████████████| 7/7 [00:01<00:00,  6.68it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     1: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.57it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     1: 100%|███████████████████████████| 7/7 [00:00<00:00,  8.63it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     2: 100%|███████████████████████████| 7/7 [00:00<00:00,  9.60it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     2: 100%|███████████████████████████| 7/7 [00:00<00:00,  8.81it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     2: 100%|███████████████████████████| 7/7 [00:00<00:00,  8.56it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     2: 100%|███████████████████████████| 7/7 [00:00<00:00,  9.39it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     3: 100%|███████████████████████████| 7/7 [00:00<00:00,  8.58it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     3: 100%|███████████████████████████| 7/7 [00:00<00:00, 10.17it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     3: 100%|███████████████████████████| 7/7 [00:00<00:00, 10.19it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     3: 100%|███████████████████████████| 7/7 [00:00<00:00, 10.02it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     4: 100%|███████████████████████████| 7/7 [00:00<00:00,  8.80it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     4: 100%|███████████████████████████| 7/7 [00:00<00:00,  8.63it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     4: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.35it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     4: 100%|███████████████████████████| 7/7 [00:01<00:00,  6.76it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     5: 100%|███████████████████████████| 7/7 [00:01<00:00,  6.90it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     5: 100%|███████████████████████████| 7/7 [00:01<00:00,  6.70it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     5: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.40it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     5: 100%|███████████████████████████| 7/7 [00:00<00:00,  8.31it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     6: 100%|███████████████████████████| 7/7 [00:00<00:00,  8.66it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     6: 100%|███████████████████████████| 7/7 [00:00<00:00, 10.12it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     6: 100%|███████████████████████████| 7/7 [00:00<00:00,  8.94it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     6: 100%|███████████████████████████| 7/7 [00:00<00:00,  8.67it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     7: 100%|███████████████████████████| 7/7 [00:00<00:00,  9.58it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     7: 100%|███████████████████████████| 7/7 [00:00<00:00,  9.06it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     7: 100%|███████████████████████████| 7/7 [00:00<00:00,  8.78it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     7: 100%|███████████████████████████| 7/7 [00:00<00:00, 10.07it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     8: 100%|███████████████████████████| 7/7 [00:00<00:00, 10.04it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     8: 100%|███████████████████████████| 7/7 [00:00<00:00,  8.91it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     8: 100%|███████████████████████████| 7/7 [00:00<00:00,  8.11it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     8: 100%|███████████████████████████| 7/7 [00:01<00:00,  6.42it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     9: 100%|███████████████████████████| 7/7 [00:01<00:00,  6.77it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     9: 100%|███████████████████████████| 7/7 [00:01<00:00,  6.58it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     9: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.16it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Train     9: 100%|███████████████████████████| 7/7 [00:00<00:00,  8.55it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Evaluate   : 100%|███████████████████| 13354/13354 [04:11<00:00, 53.19it/s, GPU RAM: 0.95 G/14.75 G]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It took 6.87 mins\n",
            "{'best_valid_score': -inf, 'valid_score_bigger': True, 'best_valid_result': None, 'test_result': OrderedDict([('recall@10', 0.0846), ('mrr@10', 0.1661), ('ndcg@10', 0.0818), ('hit@10', 0.3523), ('precision@10', 0.0469)])}\n",
            "========================================\n",
            "running ItemKNN...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:command line args [-f /root/.local/share/jupyter/runtime/kernel-ffe82819-fe22-4eb8-992f-4401f79ca9dd.json] will not be used in RecBole\n",
            "command line args [-f /root/.local/share/jupyter/runtime/kernel-ffe82819-fe22-4eb8-992f-4401f79ca9dd.json] will not be used in RecBole\n",
            "Train     0: 100%|███████████████████████| 755/755 [00:27<00:00, 27.45it/s, GPU RAM: 0.95 G/14.75 G]\n",
            "Evaluate   : 100%|███████████████████| 13354/13354 [06:20<00:00, 35.12it/s, GPU RAM: 0.95 G/14.75 G]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It took 10.06 mins\n",
            "{'best_valid_score': -inf, 'valid_score_bigger': True, 'best_valid_result': None, 'test_result': OrderedDict([('recall@10', 0.0909), ('mrr@10', 0.1768), ('ndcg@10', 0.088), ('hit@10', 0.3654), ('precision@10', 0.0504)])}\n",
            "========================================\n",
            "running DMF...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:command line args [-f /root/.local/share/jupyter/runtime/kernel-ffe82819-fe22-4eb8-992f-4401f79ca9dd.json] will not be used in RecBole\n",
            "command line args [-f /root/.local/share/jupyter/runtime/kernel-ffe82819-fe22-4eb8-992f-4401f79ca9dd.json] will not be used in RecBole\n",
            "WARNING:root:Max value of item's history interaction records has reached 44.36540621490079% of the total.\n",
            "Max value of item's history interaction records has reached 44.36540621490079% of the total.\n",
            "WARNING:root:Max value of user's history interaction records has reached 20.9471766848816% of the total.\n",
            "Max value of user's history interaction records has reached 20.9471766848816% of the total.\n",
            "Train     0: 100%|███████████████████████| 755/755 [00:50<00:00, 15.09it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     1: 100%|███████████████████████| 755/755 [00:49<00:00, 15.12it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     2: 100%|███████████████████████| 755/755 [00:50<00:00, 15.08it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     3: 100%|███████████████████████| 755/755 [00:48<00:00, 15.42it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     4: 100%|███████████████████████| 755/755 [00:49<00:00, 15.17it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     5: 100%|███████████████████████| 755/755 [00:49<00:00, 15.37it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     6: 100%|███████████████████████| 755/755 [00:49<00:00, 15.25it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     7: 100%|███████████████████████| 755/755 [00:50<00:00, 15.05it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     8: 100%|███████████████████████| 755/755 [00:49<00:00, 15.32it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     9: 100%|███████████████████████| 755/755 [00:49<00:00, 15.38it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Evaluate   : 100%|███████████████████| 13354/13354 [04:39<00:00, 47.71it/s, GPU RAM: 1.59 G/14.75 G]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It took 14.12 mins\n",
            "{'best_valid_score': -inf, 'valid_score_bigger': True, 'best_valid_result': None, 'test_result': OrderedDict([('recall@10', 0.0827), ('mrr@10', 0.1569), ('ndcg@10', 0.0781), ('hit@10', 0.3467), ('precision@10', 0.0455)])}\n",
            "========================================\n",
            "running RecVAE...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:command line args [-f /root/.local/share/jupyter/runtime/kernel-ffe82819-fe22-4eb8-992f-4401f79ca9dd.json] will not be used in RecBole\n",
            "command line args [-f /root/.local/share/jupyter/runtime/kernel-ffe82819-fe22-4eb8-992f-4401f79ca9dd.json] will not be used in RecBole\n",
            "WARNING:root:Max value of user's history interaction records has reached 20.9471766848816% of the total.\n",
            "Max value of user's history interaction records has reached 20.9471766848816% of the total.\n",
            "Train     0: 100%|███████████████████████████| 7/7 [00:01<00:00,  4.50it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     0: 100%|███████████████████████████| 7/7 [00:01<00:00,  4.58it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     0: 100%|███████████████████████████| 7/7 [00:01<00:00,  4.61it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     0: 100%|███████████████████████████| 7/7 [00:01<00:00,  4.67it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     1: 100%|███████████████████████████| 7/7 [00:01<00:00,  4.05it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     1: 100%|███████████████████████████| 7/7 [00:01<00:00,  4.76it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     1: 100%|███████████████████████████| 7/7 [00:01<00:00,  4.57it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     1: 100%|███████████████████████████| 7/7 [00:01<00:00,  4.22it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     2: 100%|███████████████████████████| 7/7 [00:03<00:00,  1.96it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     2: 100%|███████████████████████████| 7/7 [00:01<00:00,  4.72it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     2: 100%|███████████████████████████| 7/7 [00:01<00:00,  3.74it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     2: 100%|███████████████████████████| 7/7 [00:01<00:00,  3.88it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     3: 100%|███████████████████████████| 7/7 [00:01<00:00,  4.82it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     3: 100%|███████████████████████████| 7/7 [00:02<00:00,  2.48it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     3: 100%|███████████████████████████| 7/7 [00:01<00:00,  4.80it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     3: 100%|███████████████████████████| 7/7 [00:01<00:00,  4.10it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     4: 100%|███████████████████████████| 7/7 [00:03<00:00,  2.18it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     4: 100%|███████████████████████████| 7/7 [00:01<00:00,  4.83it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     4: 100%|███████████████████████████| 7/7 [00:01<00:00,  4.73it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     4: 100%|███████████████████████████| 7/7 [00:01<00:00,  4.19it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     5: 100%|███████████████████████████| 7/7 [00:18<00:00,  2.63s/it, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     5: 100%|███████████████████████████| 7/7 [00:01<00:00,  3.60it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     5: 100%|███████████████████████████| 7/7 [00:06<00:00,  1.08it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     5: 100%|███████████████████████████| 7/7 [00:13<00:00,  1.93s/it, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     6: 100%|███████████████████████████| 7/7 [00:19<00:00,  2.72s/it, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     6: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.30it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     6: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.72it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     6: 100%|███████████████████████████| 7/7 [00:00<00:00,  8.39it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     7: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.21it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     7: 100%|███████████████████████████| 7/7 [00:01<00:00,  6.19it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     7: 100%|███████████████████████████| 7/7 [00:01<00:00,  5.90it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     7: 100%|███████████████████████████| 7/7 [00:01<00:00,  6.91it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     8: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.95it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     8: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.92it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     8: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.68it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     8: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.41it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     9: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.19it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     9: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.56it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     9: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.63it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     9: 100%|███████████████████████████| 7/7 [00:00<00:00,  7.68it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Evaluate   : 100%|███████████████████| 13354/13354 [05:26<00:00, 40.86it/s, GPU RAM: 1.59 G/14.75 G]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It took 8.92 mins\n",
            "{'best_valid_score': -inf, 'valid_score_bigger': True, 'best_valid_result': None, 'test_result': OrderedDict([('recall@10', 0.0846), ('mrr@10', 0.1661), ('ndcg@10', 0.0818), ('hit@10', 0.3523), ('precision@10', 0.0469)])}\n",
            "========================================\n",
            "running ConvNCF...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:command line args [-f /root/.local/share/jupyter/runtime/kernel-ffe82819-fe22-4eb8-992f-4401f79ca9dd.json] will not be used in RecBole\n",
            "command line args [-f /root/.local/share/jupyter/runtime/kernel-ffe82819-fe22-4eb8-992f-4401f79ca9dd.json] will not be used in RecBole\n",
            "Train     0: 100%|███████████████████████| 378/378 [02:20<00:00,  2.69it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     1: 100%|███████████████████████| 378/378 [00:56<00:00,  6.67it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     2: 100%|███████████████████████| 378/378 [00:58<00:00,  6.45it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     3: 100%|███████████████████████| 378/378 [00:57<00:00,  6.53it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     4: 100%|███████████████████████| 378/378 [00:58<00:00,  6.49it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     5: 100%|███████████████████████| 378/378 [00:58<00:00,  6.47it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     6: 100%|███████████████████████| 378/378 [00:58<00:00,  6.48it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     7: 100%|███████████████████████| 378/378 [00:57<00:00,  6.55it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     8: 100%|███████████████████████| 378/378 [00:58<00:00,  6.47it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     9: 100%|███████████████████████| 378/378 [00:57<00:00,  6.58it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Evaluate   : 100%|███████████████████| 13354/13354 [09:34<00:00, 23.23it/s, GPU RAM: 1.59 G/14.75 G]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It took 22.12 mins\n",
            "{'best_valid_score': -inf, 'valid_score_bigger': True, 'best_valid_result': None, 'test_result': OrderedDict([('recall@10', 0.061), ('mrr@10', 0.1361), ('ndcg@10', 0.0628), ('hit@10', 0.2648), ('precision@10', 0.0331)])}\n",
            "========================================\n",
            "running LightGCN...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:command line args [-f /root/.local/share/jupyter/runtime/kernel-ffe82819-fe22-4eb8-992f-4401f79ca9dd.json] will not be used in RecBole\n",
            "command line args [-f /root/.local/share/jupyter/runtime/kernel-ffe82819-fe22-4eb8-992f-4401f79ca9dd.json] will not be used in RecBole\n",
            "Train     0: 100%|███████████████████████| 378/378 [00:51<00:00,  7.28it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     1: 100%|███████████████████████| 378/378 [00:52<00:00,  7.23it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     2: 100%|███████████████████████| 378/378 [00:55<00:00,  6.86it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     3: 100%|███████████████████████| 378/378 [00:52<00:00,  7.17it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     4: 100%|███████████████████████| 378/378 [00:52<00:00,  7.18it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     5: 100%|███████████████████████| 378/378 [00:52<00:00,  7.23it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     6: 100%|███████████████████████| 378/378 [00:52<00:00,  7.27it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     7: 100%|███████████████████████| 378/378 [00:52<00:00,  7.20it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     8: 100%|███████████████████████| 378/378 [00:52<00:00,  7.19it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Train     9: 100%|███████████████████████| 378/378 [00:52<00:00,  7.18it/s, GPU RAM: 1.59 G/14.75 G]\n",
            "Evaluate   : 100%|███████████████████| 13354/13354 [06:00<00:00, 37.02it/s, GPU RAM: 1.59 G/14.75 G]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It took 15.61 mins\n",
            "{'best_valid_score': -inf, 'valid_score_bigger': True, 'best_valid_result': None, 'test_result': OrderedDict([('recall@10', 0.0792), ('mrr@10', 0.1685), ('ndcg@10', 0.0795), ('hit@10', 0.3385), ('precision@10', 0.0441)])}\n",
            "========================================\n",
            "CPU times: user 1h 31min, sys: 6min 14s, total: 1h 37min 15s\n",
            "Wall time: 1h 44min 24s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "model_list = [\"MultiVAE\", \"MultiDAE\", \"MacridVAE\", \"NeuMF\", \"RecVAE\",\n",
        "              \"ItemKNN\", \"DMF\", \"ConvNCF\", \"LightGCN\"]\n",
        "\n",
        "for model_name in model_list:\n",
        "    print(f\"running {model_name}...\")\n",
        "    start = time.time()\n",
        "    result = run_recbole(model=model_name,\n",
        "                         dataset='recbox_data',\n",
        "                         config_dict=parameter_dict)\n",
        "    t = time.time() - start\n",
        "    print(f\"It took {t/60:.2f} mins\")\n",
        "    print(result)\n",
        "    print(\"==\"*20)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Лучшими моделями оказались `ItemKNN`, `RecVAE`, `MultiVAE`"
      ],
      "metadata": {
        "id": "UZboFbkiW0QL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = run_recbole(model=\"MultiVAE\",\n",
        "                     dataset=\"recbox_data\",\n",
        "                     config_dict=parameter_dict)"
      ],
      "metadata": {
        "id": "RrVFZNA_57gZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22efac2b-a189-4471-95ce-4520a627c864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:command line args [-f /root/.local/share/jupyter/runtime/kernel-38adbd9a-5a34-47f0-bcee-cd772e2c89d3.json] will not be used in RecBole\n",
            "command line args [-f /root/.local/share/jupyter/runtime/kernel-38adbd9a-5a34-47f0-bcee-cd772e2c89d3.json] will not be used in RecBole\n",
            "WARNING:root:Max value of user's history interaction records has reached 20.9471766848816% of the total.\n",
            "Max value of user's history interaction records has reached 20.9471766848816% of the total.\n",
            "Train     0: 100%|███████████████████████████| 7/7 [00:00<00:00, 15.03it/s, GPU RAM: 0.67 G/14.75 G]\n",
            "Train     1: 100%|███████████████████████████| 7/7 [00:00<00:00, 16.96it/s, GPU RAM: 0.67 G/14.75 G]\n",
            "Train     2: 100%|███████████████████████████| 7/7 [00:00<00:00, 16.31it/s, GPU RAM: 0.67 G/14.75 G]\n",
            "Train     3: 100%|███████████████████████████| 7/7 [00:00<00:00, 16.58it/s, GPU RAM: 0.67 G/14.75 G]\n",
            "Train     4: 100%|███████████████████████████| 7/7 [00:00<00:00, 16.93it/s, GPU RAM: 0.67 G/14.75 G]\n",
            "Train     5: 100%|███████████████████████████| 7/7 [00:00<00:00, 15.74it/s, GPU RAM: 0.67 G/14.75 G]\n",
            "Train     6: 100%|███████████████████████████| 7/7 [00:00<00:00, 13.57it/s, GPU RAM: 0.67 G/14.75 G]\n",
            "Train     7: 100%|███████████████████████████| 7/7 [00:00<00:00, 12.88it/s, GPU RAM: 0.67 G/14.75 G]\n",
            "Train     8: 100%|███████████████████████████| 7/7 [00:00<00:00, 12.36it/s, GPU RAM: 0.67 G/14.75 G]\n",
            "Train     9: 100%|███████████████████████████| 7/7 [00:00<00:00, 14.76it/s, GPU RAM: 0.67 G/14.75 G]\n",
            "Evaluate   : 100%|███████████████████| 13354/13354 [03:40<00:00, 60.70it/s, GPU RAM: 0.67 G/14.75 G]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultiVAE(config, dataset)\n",
        "checkpoint = torch.load(\"/content/saved/MultiVAE-Dec-13-2023_09-19-53.pth\")\n",
        "model.load_state_dict(checkpoint[\"state_dict\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUuJ4RxdXEBU",
        "outputId": "a1af9d32-3691-44f8-c7c4-525d5ea8f8b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Max value of user's history interaction records has reached 23.254401942926535% of the total.\n",
            "Max value of user's history interaction records has reached 23.254401942926535% of the total.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Напишем функцию, чтобы сделать предсказания для каждого из пользователей"
      ],
      "metadata": {
        "id": "hOSRhPp4YhHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(config[\"device\"])"
      ],
      "metadata": {
        "id": "C4mqDLcehM9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_to_user(user_id,\n",
        "                      dataset,\n",
        "                      model):\n",
        "    if user_id in dataset.field2token_id[dataset.uid_field] and user_id != \"[PAD]\":\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            uid_series = dataset.token2id(dataset.uid_field, [user_id])\n",
        "            index = np.isin(dataset[dataset.uid_field].numpy(), uid_series)\n",
        "            new_inter = dataset[index]\n",
        "            new_inter = new_inter.to(config[\"device\"])\n",
        "            new_scores = model.full_sort_predict(new_inter)\n",
        "            new_scores = new_scores.view(-1, test_data.dataset.item_num)\n",
        "            new_scores[:, 0] = -np.inf\n",
        "            recommended_item_indices = torch.topk(new_scores, 10).indices[0].tolist()\n",
        "            recos = dataset.id2token(dataset.iid_field, [recommended_item_indices]).tolist()\n",
        "        return recos\n",
        "    return []"
      ],
      "metadata": {
        "id": "jw9nSOj4YgmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommendations = {}\n",
        "users = dataset.field2token_id[dataset.uid_field]\n",
        "for user_id in users:\n",
        "    user_recs = recommend_to_user(user_id, dataset, model)\n",
        "    if user_recs:\n",
        "        recommendations |= {user_id: user_recs[0]}"
      ],
      "metadata": {
        "id": "CgolNgcfY7mS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recs = {int(user_id): list(map(lambda x: int(x), recommendations[user_id])) for user_id in recommendations}"
      ],
      "metadata": {
        "id": "k-vRQenh_LqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/MultiVAE_recs.pkl\", \"wb\") as f:\n",
        "    pickle.dump(recs, f)"
      ],
      "metadata": {
        "id": "OCFNnIFC_tzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Добавив предсказания модели в сервис и протестировав их в боте, получил метрику `MAP@10 = 0.0881563` (>0.075)"
      ],
      "metadata": {
        "id": "ESuvE0I0Avb6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "10F2BUycBFUB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}